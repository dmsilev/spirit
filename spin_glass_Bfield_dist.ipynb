{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hts = [0, 0.25, 0.5]\n",
    "\n",
    "from spirit import simulation, state,quantities, hamiltonian,parameters,geometry,configuration,system,io\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "output_interval = 2 #Interval at which spin configuration files are saved\n",
    "fn = \"dipolar_arr\"\n",
    "prefix = \"DDI_exp_14_G0p00005_Ht10p0\"\n",
    "\n",
    "iterations_per_step = 1 #Take this many Metropolis iterationss per lattice site between each check for convergence\n",
    "converge_threshold = 0.01 #Fractional change in magnetization between steps to accept convergence\n",
    "converge_max = 20 #Maximum number of steps to take before moving on\n",
    "mu = 7\n",
    "dim = 4\n",
    "concentration = 55\n",
    "\n",
    "#with state.State(\"input/test_Ising_largelattice.cfg\") as p_state:\n",
    "\n",
    "def plot_loop(Ht):\n",
    "    with state.State(f\"input/LHF_DDI_glass_14_{concentration}_tunnel_{dim}.cfg\") as p_state:\n",
    "        types = geometry.get_atom_types(p_state)\n",
    "        nos = types.size\n",
    "        print(f\"Sites: {nos}  Spins: {nos+np.sum(types)}\")\n",
    "        locs = geometry.get_positions(p_state)\n",
    "        np.savetxt(\"output/\"+prefix+\"atom_locs.csv\",locs,delimiter=\",\")\n",
    "        np.savetxt(\"output/\"+prefix+\"atom_types.csv\",types,delimiter=\",\")\n",
    "    #    write_config(p_state,prefix)\n",
    "        parameters.mc.set_metropolis_cone(p_state,use_cone=True,cone_angle=0.00000001,use_adaptive_cone=False)\n",
    "        parameters.mc.set_metropolis_spinflip(p_state,True)\n",
    "        parameters.mc.set_tunneling_gamma(p_state, tunneling_gamma=0.00012)\n",
    "\n",
    "        parameters.mc.set_temperature(p_state, 0.000000001)\n",
    "\n",
    "        #We'll evaluate convergence after enough Metropolis steps to hit each site twitce on average\n",
    "        parameters.mc.set_iterations(p_state,iterations_per_step*types.size,iterations_per_step*types.size)\n",
    "\n",
    "        #Initialize in the saturated state\n",
    "        configuration.plus_z(p_state)\n",
    "\n",
    "    ## Import the DDI interaction arrays\n",
    "    #    path_arr_x = os.path.join(\"input/\", fn +\"_DDI_x.npy\")\n",
    "    #    path_arr_y = os.path.join(\"input/\", fn +\"_DDI_y.npy\")\n",
    "    #    path_arr_z = os.path.join(\"input/\", fn +\"_DDI_z.npy\")\n",
    "        path_arr_x = os.path.join(f\"dipolar_interaction_matrices_reordered/{dim}_{dim}_{dim}/\", fn +\"_x.npy\") #fn = dipolar_arr\n",
    "        path_arr_y = os.path.join(f\"dipolar_interaction_matrices_reordered/{dim}_{dim}_{dim}/\", fn +\"_y.npy\")\n",
    "        path_arr_z = os.path.join(f\"dipolar_interaction_matrices_reordered/{dim}_{dim}_{dim}/\", fn +\"_z.npy\")\n",
    "\n",
    "        if os.path.exists(path_arr_x) and os.path.exists(path_arr_y) and os.path.exists(path_arr_z):\n",
    "            print(\"loading DDI interaction data.\")\n",
    "            DDI_interaction_x = np.load(path_arr_x)\n",
    "            DDI_interaction_y = np.load(path_arr_y)\n",
    "            DDI_interaction_z = np.load(path_arr_z)\n",
    "        else:\n",
    "            print(\"DDI files not found\")\n",
    "    #        break\n",
    "\n",
    "    #Check that the size of the DDI arrays matches NOS (extracted from the types array above).\n",
    "        if (nos != DDI_interaction_x.shape[0]) or (nos != DDI_interaction_y.shape[0]) or (nos != DDI_interaction_z.shape[0]) :\n",
    "            print(\"Size mismatch between DDI and spin array\")\n",
    "    #        break\n",
    "    #Filter out any vacant sites\n",
    "        vacancies_idx = np.where(types == -1)\n",
    "        locs[:,0][vacancies_idx] = 0\n",
    "        locs[:,1][vacancies_idx] = 0\n",
    "        locs[:,2][vacancies_idx] = 0\n",
    "\n",
    "        i = 0\n",
    "        Hz = 0\n",
    "        # for i,Hz in enumerate(fields_hyst):\n",
    "\n",
    "        print(f'{Hz:.3f}', concentration)\n",
    "\n",
    "        Hmag = np.sqrt(Hz*Hz + Ht*Ht)\n",
    "        hamiltonian.set_field(p_state,Hmag,(Ht,0,Hz)) #Inside set_field, the vector is normalized, so we don't have to do that here\n",
    "\n",
    "        spins = system.get_spin_directions(p_state)  #Get the current spin state to update the DDI fields from the Ewald sum\n",
    "        spins[:,2][vacancies_idx] = 0   #For LHF, we only care about Sz, but zero out the moments for vacancy site\n",
    "\n",
    "        #Calculate the DDI field components, and then send to the SPIRIT engine. DDI interaction calculations are in Oe, SPIRIT\n",
    "        #uses T, so need to scale accordingly.\n",
    "        #Get the field at each spin. Only care about DDI due to z-spin so use spins[:,2]\n",
    "        DDI_field_x = np.matmul(DDI_interaction_x,spins[:,2]) *7/1e4\n",
    "        DDI_field_y = np.matmul(DDI_interaction_y,spins[:,2]) *7/1e4\n",
    "        DDI_field_z = np.matmul(DDI_interaction_z,spins[:,2]) *7/1e4\n",
    "\n",
    "        #Pass into SPIRIT\n",
    "        DDI_field_interleave = np.ravel(np.column_stack((DDI_field_x,DDI_field_y,DDI_field_z)))\n",
    "        system.set_DDI_field(p_state,n_atoms=nos,ddi_fields=DDI_field_interleave)\n",
    "        # print(f\"X: mean: {np.mean(DDI_field_x):.4e} Std. Dev: {np.std(DDI_field_x):.4e}\")\n",
    "        # print(f\"Y: mean: {np.mean(DDI_field_y):.4e} Std. Dev: {np.std(DDI_field_y):.4e}\")\n",
    "        print(f\"Z: mean: {np.mean(DDI_field_z):.4e} Std. Dev: {np.std(DDI_field_z):.4e}\")\n",
    "\n",
    "        #Check convergence, same as old hysteresis_loop. But METHOD_MC now uses tunnelling since we set tunnel flag to 1 in cfg files\n",
    "        for j in range(converge_max) :\n",
    "            simulation.start(p_state, simulation.METHOD_MC, single_shot=False) #solver_type=simulation.MC_ALGORITHM_METROPOLIS\n",
    "            simulation.stop(p_state)\n",
    "            if j == 0 :\n",
    "                m_temp = quantities.get_magnetization(p_state)[2]\n",
    "            else :\n",
    "                m_prev = m_temp\n",
    "                m_temp = quantities.get_magnetization(p_state)[2]\n",
    " #               ratio = abs((m_temp-m_prev)/m_prev)\n",
    "                ratio = abs((m_temp-m_prev)/mu)\n",
    "                print(f\"Iteration: {j:d}, Convergence: {ratio:.4f}, M_z: {m_temp:.4f}\")\n",
    "                if ratio<converge_threshold :\n",
    "                    break\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == '__main__':\n",
    "    # spin_concentrations = [85, 95, 15, 25, 35, 45, 55, 65, 75]\n",
    "    n_cycles = 1\n",
    "    conc = 55\n",
    "    # spin_concentrations = [conc] * n_cycles\n",
    "\n",
    "    # Assuming fields_hyst and mz are already defined\n",
    "\n",
    "    with mp.Pool(processes=3) as pool:\n",
    "        results = pool.map(plot_loop, Hts)"
   ],
   "id": "d60fb17bc6876910"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:44:06.169100Z",
     "start_time": "2025-07-06T16:44:06.164701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from spirit import simulation, state,quantities, hamiltonian,parameters,geometry,configuration,system,io\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "concentration = 25\n",
    "dim = 4"
   ],
   "id": "a2e438389463f7b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T16:44:43.646318Z",
     "start_time": "2025-07-06T16:44:43.566563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with state.State(f\"input/LHF_DDI_glass_14_{concentration}_tunnel_{dim}.cfg\") as p_state:\n",
    "    print(type(p_state))"
   ],
   "id": "6e4ba0a1e8165528",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-06 09:44:43  [  ALL  ] [ALL ] [--] [--]  =====================================================\n",
      "                                                 ========== Spirit State: Initialising... ============\n",
      "                                                 ==========     Version:  2.2.0\n",
      "                                                 ==========     Revision: 57bb4f9adb68c\n",
      "2025-07-06 09:44:43  [  ALL  ] [ALL ] [--] [--]  Config file: \"input/LHF_DDI_glass_14_25_tunnel_4.cfg\"\n",
      "2025-07-06 09:44:43  [  ALL  ] [ALL ] [--] [--]  =====================================================\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  Keyword 'lattice_rng_seed' not found. Using Default: -332800635\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  4 atom types, iatom=0 atom type=0 concentration=0.25\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  Keyword 'mc_seed' not found. Using Default: -1083652157\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  Keyword 'ema_sparse' not found. Using Default: false\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  Keyword 'cubic_anisotropy_magnitude' not found. Using Default: 0\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  Keyword 'gneb_moving_endpoints' not found. Using Default: false\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  Keyword 'gneb_equilibrium_delta_Rx_left' not found. Using Default: 1\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  Keyword 'gneb_equilibrium_delta_Rx_right' not found. Using Default: 1\n",
      "2025-07-06 09:44:43  [WARNING] [ IO ] [--] [--]  Keyword 'gneb_translating_endpoints' not found. Using Default: false\n",
      "2025-07-06 09:44:43  [  ALL  ] [ALL ] [--] [--]  =====================================================\n",
      "                                                 ============ Spirit State: Initialised ==============\n",
      "                                                 ============     NOS=256 NOI=1\n",
      "                                                     Initialisation took 0:0:0.76\n",
      "                                                     Number of  Errors:  0\n",
      "                                                     Number of Warnings: 36\n",
      "                                                 =====================================================\n",
      "<class 'int'>\n",
      "2025-07-06 09:44:43  [  ALL  ] [ALL ] [--] [--]  =====================================================\n",
      "                                                 ============ Spirit State: Deleting... ==============\n",
      "                                                     State existed for 0:0:0.76\n",
      "                                                     Number of  Errors:  0\n",
      "                                                     Number of Warnings: 36\n",
      "                                                 ============== Spirit State: Deleted ================\n",
      "                                                 =====================================================\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "22c37d6b7eeeb65b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
